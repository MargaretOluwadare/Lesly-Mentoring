{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b59b1e",
   "metadata": {},
   "source": [
    "## Basic Recommendation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec2496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample data: Product IDs and their descriptions\n",
    "products_data = {\n",
    "    'product_id': [1, 2, 3, 4, 5],\n",
    "    'product_name': ['Smartphone', 'Laptop', 'Headphones', 'Smartwatch', 'Tablet'],\n",
    "    'category': ['Electronics', 'Electronics', 'Accessories', 'Electronics', 'Electronics'],\n",
    "    'description': [\n",
    "        'Latest model with great battery life and high-end features',\n",
    "        'Powerful laptop with fast processor and good storage',\n",
    "        'Noise-cancelling headphones with deep bass and comfort',\n",
    "        'Stylish smartwatch with fitness tracking and heart rate monitor',\n",
    "        'Portable tablet with a sleek design and great screen resolution'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_products = pd.DataFrame(products_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c10ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Products:\n",
      "  product_name                                        description\n",
      "1       Laptop  Powerful laptop with fast processor and good s...\n",
      "4       Tablet  Portable tablet with a sleek design and great ...\n",
      "3   Smartwatch  Stylish smartwatch with fitness tracking and h...\n"
     ]
    }
   ],
   "source": [
    "# Function to recommend products based on user preferences\n",
    "def recommend_products(user_preferences, num_recommendations=3):\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Fit the TF-IDF model on the product descriptions\n",
    "    tfidf_matrix = tfidf.fit_transform(df_products['description'])\n",
    "    \n",
    "    # Compute cosine similarity between user preferences and products\n",
    "    user_tfidf = tfidf.transform([user_preferences])\n",
    "    cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    \n",
    "    # Get the indices of the most similar products\n",
    "    similar_products_idx = cosine_sim[0].argsort()[-num_recommendations:][::-1]\n",
    "    \n",
    "    # Get recommended products\n",
    "    recommended_products = df_products.iloc[similar_products_idx]\n",
    "    \n",
    "    return recommended_products[['product_name', 'description']]\n",
    "\n",
    "# Example: A user preferences string\n",
    "user_preferences = \"I like powerful laptops with fast processors and good storage\"\n",
    "\n",
    "# Get recommendations\n",
    "recommendations = recommend_products(user_preferences)\n",
    "print(\"Recommended Products:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff56eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "539774b7",
   "metadata": {},
   "source": [
    "## Movie Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ea8b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
      "Collecting scikit-surprise (from surprise)\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "     ---------------------------------------- 0.0/154.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/154.4 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/154.4 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/154.4 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/154.4 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 61.4/154.4 kB 409.6 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 102.4/154.4 kB 535.8 kB/s eta 0:00:01\n",
      "     -----------------------------------  153.6/154.4 kB 654.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 154.4/154.4 kB 576.8 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hello\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hello\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hello\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.10.1)\n",
      "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-win_amd64.whl size=1296652 sha256=896c4bba4f70ee64b727587a37a79750802aa13f78405663e85ef596c8a36ca5\n",
      "  Stored in directory: c:\\users\\hello\\appdata\\local\\pip\\cache\\wheels\\2a\\8f\\6e\\7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce84a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp  title\n",
      "0      308         1       4  887736532      0\n",
      "1      308         1       4  887736532      0\n",
      "2      308         1       4  887736532      0\n",
      "3      308         1       4  887736532      0\n",
      "4      308         1       4  887736532      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "file_path = 'ml-100k/u.data'\n",
    "\n",
    "# Load the ratings data\n",
    "df_ratings = pd.read_csv(file_path, sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'], header=None)\n",
    "\n",
    "# Load movie metadata\n",
    "movie_file_path = 'ml-100k/u.item'\n",
    "df_movies = pd.read_csv(movie_file_path, sep='|', names=['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'], encoding='latin-1')\n",
    "\n",
    "# Merge dataframes to have movie titles along with ratings\n",
    "df_ratings_with_titles = pd.merge(df_ratings, df_movies[['movie_id', 'title']], on='movie_id')\n",
    "\n",
    "# Show the first few rows of the ratings data\n",
    "print(df_ratings_with_titles.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392dcd9",
   "metadata": {},
   "source": [
    "we will use the SVD (Singular Value Decomposition) algorithm for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e343c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4ebaa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9284478560687779"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Reader\n",
    "\n",
    "# Define the data format for the Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Use the SVD algorithm\n",
    "svd = SVD()\n",
    "\n",
    "# Train the model\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Make predictions\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab8d3143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2's ratings:\n",
      "       user_id  movie_id  rating  timestamp\n",
      "700          2       292       4  888550774\n",
      "924          2       251       5  888552084\n",
      "1052         2        50       5  888552084\n",
      "3425         2       314       1  888980085\n",
      "5063         2       297       4  888550871\n",
      "...        ...       ...     ...        ...\n",
      "77906        2       288       3  888550252\n",
      "85606        2       286       4  888549960\n",
      "88190        2       275       5  888550939\n",
      "95677        2       302       5  888552084\n",
      "97619        2       296       3  888550871\n",
      "\n",
      "[62 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"User 2's ratings:\")\n",
    "print(df_ratings[df_ratings['user_id'] == 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5308f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Define the user_id you want to get recommendations for\n",
    "user_id = 4  # Replace with the appropriate user ID\n",
    "\n",
    "# Now, use the user_id to filter the ratings\n",
    "rated_movies = df_ratings[df_ratings['user_id'] == user_id]['movie_id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfdf6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_recommendations(user_id):\n",
    "    # Get all movie IDs\n",
    "    all_movie_ids = df_movies_clean['movie_id'].tolist()\n",
    "\n",
    "    # Get a list of movie IDs that the user has already rated\n",
    "    rated_movies = df_ratings[df_ratings['user_id'] == user_id]['movie_id'].tolist()\n",
    "    \n",
    "    # Debug: Check user-rated movies\n",
    "    print(f\"User {user_id} has rated {len(rated_movies)} movies.\")\n",
    "    print(f\"Rated movie IDs: {rated_movies}\")\n",
    "\n",
    "    # Filter out movies that the user has already rated\n",
    "    movies_to_predict = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n",
    "    \n",
    "    # Debug: Check valid movies for prediction\n",
    "    print(f\"Movies to predict for user {user_id}: {movies_to_predict[:10]}\")  # Show first 10 for debugging\n",
    "\n",
    "    if not movies_to_predict:\n",
    "        print(\"No valid movies to predict.\")\n",
    "        return []\n",
    "\n",
    "    # Get the predicted ratings for the valid movies\n",
    "    predictions = [svd.predict(user_id, movie_id) for movie_id in movies_to_predict]\n",
    "    \n",
    "    # Sort predictions by estimated rating (highest first)\n",
    "    sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Get top N movie recommendations\n",
    "    top_recommendations = sorted_predictions[:5]\n",
    "\n",
    "    recommended_movies = []\n",
    "    for prediction in top_recommendations:\n",
    "        movie_id = prediction.iid\n",
    "        movie_title = df_movies_clean[df_movies_clean['movie_id'] == movie_id]['title'].values[0]\n",
    "        recommended_movies.append(movie_title)\n",
    "\n",
    "    # Return recommended movies\n",
    "    return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af5b1bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 4 has rated 24 movies.\n",
      "Rated movie IDs: [264, 303, 361, 357, 260, 356, 294, 288, 50, 354, 271, 300, 328, 258, 210, 329, 11, 327, 324, 359, 362, 358, 360, 301]\n",
      "Movies to predict for user 4: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Top 5 Movie Recommendations for User 4:\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Test with user ID 4 (or any other valid user ID)\n",
    "user_id = 4\n",
    "recommended_movies = get_movie_recommendations(user_id)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Top 5 Movie Recommendations for User 4:\")\n",
    "for movie in recommended_movies:\n",
    "    print(movie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d90471",
   "metadata": {},
   "source": [
    "### Using a different filtering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3daa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load movie metadata\n",
    "movie_file_path = 'ml-100k/u.item'\n",
    "df_movies = pd.read_csv(movie_file_path, sep='|', names=['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url', 'unknown', 'action', 'adventure', 'animation', 'children', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'horror', 'musical', 'mystery', 'romance', 'sci_fi', 'thriller', 'war', 'western'], encoding='latin-1')\n",
    "\n",
    "# Select relevant columns (genres here, but you can add other features)\n",
    "df_movies['genres'] = df_movies.iloc[:, 6:].apply(lambda row: ' '.join(row.index[row == 1]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24f06aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize genres using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df_movies['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25dea67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between all movies\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f30ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID 1 not found in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Check if the movie_id exists in the dataframe\n",
    "movie_id_to_test = 1\n",
    "if movie_id_to_test in df_movies['movie_id'].values:\n",
    "    recommended_movies = get_content_based_recommendations(movie_id=movie_id_to_test)\n",
    "    print(\"Top 5 Content-Based Recommendations:\")\n",
    "    for movie in recommended_movies:\n",
    "        print(movie)\n",
    "else:\n",
    "    print(f\"Movie ID {movie_id_to_test} not found in the dataframe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "488115c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum movie ID: 'Til There Was You (1997)\n",
      "Maximum movie ID: Á köldum klaka (Cold Fever) (1994)\n"
     ]
    }
   ],
   "source": [
    "# Check the range of movie IDs in df_movies\n",
    "print(\"Minimum movie ID:\", df_movies['movie_id'].min())\n",
    "print(\"Maximum movie ID:\", df_movies['movie_id'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96857352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                    movie_id  \\\n",
      "1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0         0   \n",
      "2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0         0   \n",
      "3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0         0   \n",
      "4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0         0   \n",
      "5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0         0   \n",
      "\n",
      "                                                                                                                    title  \\\n",
      "1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0      0   \n",
      "2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0      0   \n",
      "3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0      0   \n",
      "4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0      0   \n",
      "5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0      0   \n",
      "\n",
      "                                                                                                                    release_date  \\\n",
      "1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0             0   \n",
      "2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0             1   \n",
      "3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0             1   \n",
      "4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0             0   \n",
      "5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0             1   \n",
      "\n",
      "                                                                                                                    video_release_date  \\\n",
      "1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0                   0   \n",
      "2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0                   0   \n",
      "3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0                   0   \n",
      "4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0                   0   \n",
      "5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0                   0   \n",
      "\n",
      "                                                                                                                    imdb_url  \n",
      "1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0         0  \n",
      "2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0         0  \n",
      "3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0         0  \n",
      "4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0         0  \n",
      "5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0         0  \n"
     ]
    }
   ],
   "source": [
    "# Load the movie data with a proper header (if the first row contains actual data and not column names)\n",
    "df_movies = pd.read_csv(movie_file_path, sep='|', header=None, names=['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'], encoding='latin-1')\n",
    "\n",
    "# Check the first few rows\n",
    "print(df_movies.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe90d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc7d8ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                  1            2   3   \\\n",
      "0   1   Toy Story (1995)  01-Jan-1995 NaN   \n",
      "1   2   GoldenEye (1995)  01-Jan-1995 NaN   \n",
      "2   3  Four Rooms (1995)  01-Jan-1995 NaN   \n",
      "3   4  Get Shorty (1995)  01-Jan-1995 NaN   \n",
      "4   5     Copycat (1995)  01-Jan-1995 NaN   \n",
      "\n",
      "                                                  4   5   6   7   8   9   ...  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...   0   0   0   1   1  ...   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...   0   1   1   0   0  ...   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...   0   0   0   0   0  ...   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...   0   1   0   0   0  ...   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)   0   0   0   0   0  ...   \n",
      "\n",
      "   14  15  16  17  18  19  20  21  22  23  \n",
      "0   0   0   0   0   0   0   0   0   0   0  \n",
      "1   0   0   0   0   0   0   0   1   0   0  \n",
      "2   0   0   0   0   0   0   0   1   0   0  \n",
      "3   0   0   0   0   0   0   0   0   0   0  \n",
      "4   0   0   0   0   0   0   0   1   0   0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "   movie_id              title\n",
      "0         1   Toy Story (1995)\n",
      "1         2   GoldenEye (1995)\n",
      "2         3  Four Rooms (1995)\n",
      "3         4  Get Shorty (1995)\n",
      "4         5     Copycat (1995)\n",
      "movie_id                int32\n",
      "title                  object\n",
      "release_date           object\n",
      "video_release_date    float64\n",
      "imdb_url               object\n",
      "genre_0                 int64\n",
      "genre_1                 int64\n",
      "genre_2                 int64\n",
      "genre_3                 int64\n",
      "genre_4                 int64\n",
      "genre_5                 int64\n",
      "genre_6                 int64\n",
      "genre_7                 int64\n",
      "genre_8                 int64\n",
      "genre_9                 int64\n",
      "genre_10                int64\n",
      "genre_11                int64\n",
      "genre_12                int64\n",
      "genre_13                int64\n",
      "genre_14                int64\n",
      "genre_15                int64\n",
      "genre_16                int64\n",
      "genre_17                int64\n",
      "genre_18                int64\n",
      "dtype: object\n",
      "Minimum movie ID: 1\n",
      "Maximum movie ID: 1682\n",
      "   movie_id              title\n",
      "0         1   Toy Story (1995)\n",
      "1         2   GoldenEye (1995)\n",
      "2         3  Four Rooms (1995)\n",
      "3         4  Get Shorty (1995)\n",
      "4         5     Copycat (1995)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assuming '|' is the delimiter and encoding is 'latin-1')\n",
    "movie_file_path = 'ml-100k/u.item'  # Update this path as needed\n",
    "df_movies = pd.read_csv(movie_file_path, sep='|', header=None, encoding='latin-1')\n",
    "\n",
    "# Inspect the first few rows to see the data structure\n",
    "print(df_movies.head())\n",
    "\n",
    "# Define column names based on the expected format\n",
    "df_movies.columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'] + [f'genre_{i}' for i in range(19)]\n",
    "\n",
    "# Check the first few rows again with proper column names\n",
    "print(df_movies[['movie_id', 'title']].head())\n",
    "\n",
    "# Clean the 'movie_id' column to ensure it's numeric (and handle extra spaces or characters)\n",
    "df_movies['movie_id'] = df_movies['movie_id'].astype(str).str.strip().astype(int)\n",
    "\n",
    "# Ensure movie_id column is of type int\n",
    "print(df_movies.dtypes)\n",
    "\n",
    "# Check the minimum and maximum movie_id\n",
    "print(\"Minimum movie ID:\", df_movies['movie_id'].min())\n",
    "print(\"Maximum movie ID:\", df_movies['movie_id'].max())\n",
    "\n",
    "# Check the first few rows of cleaned data\n",
    "print(df_movies[['movie_id', 'title']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e93105ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Content-Based Recommendations for user 4:\n",
      "Faster Pussycat! Kill! Kill! (1965)\n",
      "Best Men (1997)\n",
      "Doom Generation, The (1995)\n",
      "Eat Drink Man Woman (1994)\n",
      "Ed Wood (1994)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Extract genre columns (from 'genre_0' to 'genre_18')\n",
    "genre_columns = [f'genre_{i}' for i in range(19)]\n",
    "movie_features = df_movies[genre_columns]\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(movie_features)\n",
    "\n",
    "# Function to get movie recommendations\n",
    "def get_content_based_recommendations(movie_id, top_n=5):\n",
    "    # Get the index of the movie\n",
    "    idx = df_movies[df_movies['movie_id'] == movie_id].index[0]\n",
    "\n",
    "    # Get pairwise similarity scores of all movies with the given movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on similarity score\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top N most similar movies\n",
    "    top_similar_movies = sim_scores[1:top_n+1]  # Exclude the first one as it is the movie itself\n",
    "    \n",
    "    # Get movie IDs and titles of the top N similar movies\n",
    "    recommended_movie_ids = [df_movies.iloc[i[0]]['movie_id'] for i in top_similar_movies]\n",
    "    recommended_movie_titles = [df_movies.iloc[i[0]]['title'] for i in top_similar_movies]\n",
    "    \n",
    "    return recommended_movie_titles\n",
    "\n",
    "# Test the recommendation system \n",
    "recommended_movies = get_content_based_recommendations(movie_id=4)\n",
    "print(\"Top 5 Content-Based Recommendations for user 4:\")\n",
    "for movie in recommended_movies:\n",
    "    print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f6316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
